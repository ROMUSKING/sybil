# Generic section for API keys. The key name (e.g., 'openai') should correspond
# to the environment variable LiteLLM expects (e.g., OPENAI_API_KEY).
api_keys:
  openai: "YOUR_OPENAI_KEY"
  anthropic: "YOUR_ANTHROPIC_KEY"
  openrouter: "YOUR_OPENROUTER_KEY"
  # Add other providers or proxies here, e.g.:
  # together_ai: "YOUR_TOGETHER_AI_KEY"

# This section maps a friendly, user-defined name to the specific
# model string that LiteLLM requires.
models:
  "gpt-4-direct":
    litellm_model_name: "gpt-4"
  "claude-opus-direct":
    litellm_model_name: "claude-3-opus-20240229"
  "openrouter-mixtral":
    litellm_model_name: "openrouter/mistralai/mixtral-8x7b-instruct"
  # Example of another proxied model
  # "together-llama3":
  #   litellm_model_name: "together_ai/meta-llama/Llama-3-70b-chat-hf"

# Assign a friendly model name to each agent role. The ModelManager will
# handle routing it to the correct provider based on the 'models' mapping.
agent_models:
  architect: "claude-opus-direct"
  developer: "openrouter-mixtral"
  reviewer: "gpt-4-direct"
